"""
Report Generation Module
========================

Generates markdown scorecards and summary reports from pipeline results.

Synthetic demo output for portfolio purposes.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Optional
import logging

from .validate import ValidationReport
from .metrics import MetricsReport

logger = logging.getLogger(__name__)


def generate_scorecard_markdown(
    validation: ValidationReport,
    metrics: MetricsReport,
    input_file: str,
    output_path: Optional[Path] = None
) -> str:
    """
    Generate a markdown scorecard summarizing the pipeline run.

    Args:
        validation: Validation results
        metrics: Computed KPI metrics
        input_file: Name of input file processed
        output_path: Optional path to write the markdown file

    Returns:
        Markdown string
    """
    timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')

    # Build validation summary table
    validation_rows = []
    for check in validation.results:
        status = "✓" if check.passed else ("⚠" if check.severity == "WARN" else "✗")
        validation_rows.append(
            f"| {check.check_name} | {check.severity} | {status} | {check.message} |"
        )
    validation_table = "\n".join(validation_rows) if validation_rows else "| No checks | - | - | - |"

    # Build KPI summary table
    kpi_rows = []
    for kpi in metrics.kpis:
        if isinstance(kpi.value, dict):
            # For breakdown KPIs, show count of categories
            value_str = f"{len(kpi.value)} categories"
        else:
            value_str = f"{kpi.value:,}" if isinstance(kpi.value, (int, float)) else str(kpi.value)
        kpi_rows.append(
            f"| {kpi.kpi_id} | {kpi.name} | {value_str} | {kpi.unit} |"
        )
    kpi_table = "\n".join(kpi_rows) if kpi_rows else "| No KPIs | - | - | - |"

    # Overall status
    overall_status = "✓ PASSED" if validation.passed else "✗ FAILED"

    markdown = f"""# Demo Pipeline Run Scorecard

> **Synthetic demo output for portfolio purposes.**

---

## Run Summary

| Property | Value |
|----------|-------|
| **Timestamp** | {timestamp} |
| **Input File** | {input_file} |
| **Total Rows** | {validation.total_rows:,} |
| **Valid Rows** | {validation.valid_rows:,} |
| **Quarantined Rows** | {validation.quarantined_rows:,} |
| **Status** | {overall_status} |

---

## Validation Results

| Check | Severity | Status | Message |
|-------|----------|--------|---------|
{validation_table}

**Summary**: {validation.blocker_count} blockers, {validation.warning_count} warnings

---

## KPI Metrics

| ID | Name | Value | Unit |
|----|------|-------|------|
{kpi_table}

---

## Category Breakdowns

"""

    # Add detailed breakdowns for dict-type KPIs
    for kpi in metrics.kpis:
        if isinstance(kpi.value, dict) and kpi.value:
            markdown += f"### {kpi.name}\n\n"
            markdown += "| Category | Value |\n|----------|-------|\n"
            for cat, val in sorted(kpi.value.items(), key=lambda x: -x[1] if isinstance(x[1], (int, float)) else 0):
                val_str = f"${val:,.2f}" if kpi.unit == "USD" else f"{val:,}"
                markdown += f"| {cat} | {val_str} |\n"
            markdown += "\n"

    markdown += """---

## Next Steps

- Review quarantined records for data quality issues
- Investigate any validation warnings
- Use KPI results for reporting and dashboards

---

*Generated by Demo Pipeline v1.0.0*
"""

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(markdown)
        logger.info(f"Scorecard written to {output_path}")

    return markdown


def generate_metrics_json(
    metrics: MetricsReport,
    output_path: Optional[Path] = None
) -> dict:
    """
    Export metrics to JSON format.

    Args:
        metrics: Computed KPI metrics
        output_path: Optional path to write JSON file

    Returns:
        Dict representation of metrics
    """
    data = metrics.to_dict()
    data['generated_at'] = datetime.utcnow().isoformat() + 'Z'

    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        logger.info(f"Metrics JSON written to {output_path}")

    return data
